{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from flask import Flask,request,jsonify\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe331f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start from here\n",
    "thread1 = threading.Thread(target = crawler,args=(190000,191000))\n",
    "thread2 = threading.Thread(target = crawler,args=(191000,192000))\n",
    "thread3 = threading.Thread(target = crawler,args=(192000,193000))\n",
    "thread4 = threading.Thread(target = crawler,args=(193000,194000))\n",
    "thread5 = threading.Thread(target = crawler,args=(194000,195000))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "thread4.start()\n",
    "thread5.start()\n",
    "\n",
    "\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "thread4.join()\n",
    "thread5.join()\n",
    "print(\"all done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7b6b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client['recipe_db']\n",
    "collection = db.recipe_collection\n",
    "\n",
    "# num = 1000\n",
    "def crawler(start,end):\n",
    "    for i in range(start,end):\n",
    "        try : \n",
    "            url = 'https://icook.tw/recipes/{}'.format(i)\n",
    "            userAgent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "            headers = {\n",
    "            'User-Agent':userAgent\n",
    "            }\n",
    "            ss = requests.session()\n",
    "            response = ss.get(url,headers=headers)\n",
    "            soup = BeautifulSoup(response.text,'html.parser')\n",
    "            soup\n",
    "            ingredientDict = {} \n",
    "            cooking_step = {}\n",
    "            cooking_step_list = []\n",
    "\n",
    "            dish_info = {}\n",
    "\n",
    "            # dish_name\n",
    "            dish_name = soup.select('h1[class=\"title\"]')[0].text.strip()\n",
    "            dish_info['DishName'] = dish_name\n",
    "\n",
    "            # dishid\n",
    "            dishid = i\n",
    "            dish_info['dishid']= i\n",
    "\n",
    "            # author\n",
    "            authorname = soup.select('div[class=\"author-name\"]')[0].text.strip()\n",
    "            dish_info['author'] = authorname\n",
    "\n",
    "\n",
    "            # author info\n",
    "            try:\n",
    "                author_info_list = soup.select('span[class=\"author-stat\"]')\n",
    "                author_recipe = author_info_list[0].select('span[class=\"stat-num\"]')[0].text\n",
    "                author_fans = author_info_list[1].select('span[class=\"stat-num\"]')[0].text\n",
    "                author_info = {'author_recipe':author_recipe,'author_fans':author_fans}\n",
    "                dish_info['author_info'] = author_info\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # imageurl\n",
    "            imageUrl = soup.select('div[class=\"recipe-cover\"]')[0].select('img')[0]['src']\n",
    "            dish_info['imageUrl'] = imageUrl\n",
    "            resImg = requests.get(imageUrl, headers=headers)\n",
    "            resContent = resImg.content  # 取出來的資料為二進制內容\n",
    "            with open('./recipe_photo/{}.jpg'.format(dishid),'wb') as file:\n",
    "                file.write(resContent)\n",
    "\n",
    "            # description\n",
    "            try:\n",
    "                descriptiontext = soup.select('section[class=\"description\"]')[0].select('p')[0].text\n",
    "                dish_info['description'] = descriptiontext\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # portion\n",
    "            try:\n",
    "                portion = soup.select('div[class=\"servings\"]')[0].select('span[class=\"num\"]')[0].text\n",
    "                dish_info['portion'] = portion\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # cooking time\n",
    "            try:\n",
    "                time = soup.select('div[class=\"info-content\"]')[1].select('span[class=\"num\"]')[0].text\n",
    "                dish_info['cooking_time'] = time\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # ingredient\n",
    "            ingredient_name_list = soup.select('div[class=\"ingredient-name\"]')\n",
    "            ingredient_unit_list = soup.select('div[class=\"ingredient-unit\"]')\n",
    "\n",
    "            for i in range(len(ingredient_name_list)): \n",
    "                ingredient_name = ingredient_name_list[i].text.strip()\n",
    "                ingredient_unit = ingredient_unit_list[i].text\n",
    "                ingredientDict[ingredient_name] = ingredient_unit\n",
    "\n",
    "            dish_info['ingredient'] = ingredientDict\n",
    "\n",
    "            #cooking steps\n",
    "            steps = soup.select('ul[class=\"recipe-details-steps\"]')[0].text.strip().split('\\n')\n",
    "            for item in steps:\n",
    "                if len(item) > 1:\n",
    "                    cooking_step_list.append(item)\n",
    "\n",
    "            dish_info['cooking_step'] = cooking_step_list\n",
    "\n",
    "            # tag \n",
    "            try:\n",
    "                tagList = soup.select('ul[class=\"breadcrumb\"]')\n",
    "                if len(tagList) >=1:\n",
    "                    tag = []\n",
    "                    for item in tagList:\n",
    "                        try:\n",
    "                            tag.append(item.select('li[class=\"breadcrumb-item\"]')[2].text.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            tag.append(item.select('li[class=\"breadcrumb-item\"]')[3].text.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    dish_info['tags'] = tag\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # likes\n",
    "            try : \n",
    "                likesnum = soup.select('span[class=\"stat-left\"]')[0].select('span[class=\"stat-content\"]')[0].text\n",
    "                dish_info['likes'] = likesnum\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # views\n",
    "            views = soup.select('div[class=\"recipe-detail-meta-item\"]')[0].text.strip()\n",
    "            dish_info['views'] = views\n",
    "\n",
    "    #         print(dish_info)\n",
    "            recipe_id = collection.insert_one(dish_info).inserted_id\n",
    "            print(f'recipe {dishid} saved seccessfully.')\n",
    "        except:\n",
    "            print(f'recipe {i} not found')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
